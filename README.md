# ğŸ“š Chat Interactivo con Carga de Archivos â€“ Shiny para Python

Esta es una aplicaciÃ³n web tipo chat desarrollada con [Shiny para Python](https://shiny.posit.co/py/), que permite mantener conversaciones con un modelo de lenguaje (OpenAI) y cargar documentos PDF o imÃ¡genes para contextualizar las respuestas. Incluye autenticaciÃ³n bÃ¡sica, historial persistente de conversaciones, manejo de archivos y una interfaz interactiva adaptable.

## ğŸš€ CaracterÃ­sticas

-   Iterfaz moderna tipo ChatGPT.

-   Historial persistente de chats por usuario.

-   Renombrar y eliminar conversaciones.

-   Scroll automÃ¡tico y animaciones.

-   Carga de archivos (PDF, PNG, JPG) para extraer contexto.

-   IntegraciÃ³n con OpenAI GPT para generaciÃ³n de respuestas.

-   ConfiguraciÃ³n flexible vÃ­a archivos YAML (`paths.yaml`, `llm.yaml`).

-   SeparaciÃ³n modular en funciones de configuraciÃ³n y utilidades.

## ğŸ§© Estructura del Proyecto

``` bash
project/
â”‚
â”œâ”€â”€ .env.template                  # API key de OpenAI
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requierements.txt
â”œâ”€â”€ renv.lock
â””â”€â”€ src
    â”‚
    â”œâ”€â”€ app.py                     # CÃ³digo principal de la app
    â”œâ”€â”€ config/
    â”‚   â”‚
    â”‚   â”œâ”€â”€ paths.yaml             # Rutas a recursos estÃ¡ticos, estilos, logo, etc.
    â”‚   â””â”€â”€ llm.yaml               # ConfiguraciÃ³n del modelo LLM
    â”‚
    â”œâ”€â”€ css/
    â”‚    â”‚
    â”‚    â””â”€â”€ styles.css            # Archivos de estilos
    â”‚
    â”œâ”€â”€ db/
    â”‚    â”‚
    â”‚    â””â”€â”€ user_chats/
    â”‚        â”‚
    â”‚        â””â”€â”€ usuario_demo/     # Carpeta donde se almacenan los historiales por usuario
    â”‚
    â”œâ”€â”€ utils/
    â”‚   â”‚
    â”‚   â”œâ”€â”€ config_functions.py    # Carga y resoluciÃ³n de rutas desde YAML
    â”‚   â””â”€â”€ utils_functions.py     # Manejo de sesiÃ³n, archivos, extracciÃ³n de texto, etc.
    â”‚
    â”œâ”€â”€ www/                       # Archivos estÃ¡ticos (logo, otros)
    â”‚   â”‚
    â”‚   â””â”€â”€ my_logo.png            # Archivo del logo de la aplicaciÃ³n
    â”‚
    â””â”€â”€ data/                      # Carpeta donde se colocan los archivos .pdf, .jpg o .png que se usarÃ­an para extraer contexto
```

## ğŸ§ª Requisitos

-   Python 3.9+
-   shiny
-   openai
-   python-dotenv
-   librerÃ­as auxiliares como `PyMuPDF` (para PDF), `pytesseract` (para OCR)

InstalaciÃ³n rÃ¡pida:

``` bash
pip install -r requirements.txt
```

Si usas [`renv`](https://rstudio.github.io/renv/articles/python.html) puedes ejecutar el siguiente comando para instalar las librerÃ­as python desde el `requirements.txt`:

``` bash
renv::restore()
```

## âš™ï¸ ConfiguraciÃ³n

1.  Claves de API

    Cambia el nombre del archivo `.env.template` a `.env`, y luego pega tu clave de OpenAI:

``` env
# OpenAI (estandar)
OPENAI_API_KEY = 'sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'
```

2.  ConfiguraciÃ³n de rutas (`paths.yaml`)

    Contenido:

``` yaml
# Data base path
data_base_folder_path: '../db/user_chats'

# Static assets path
statics:
    folder_path: '../www'
    logo_file_name: 'my_logo.png'

# Styles css file path
styles_file_path: '../css/styles.css'

# Tesseract path
tesseract_exe_path: 'C:/path/to/Tesseract-OCR/tesseract.exe'
```

En el archivo anterior, solo debes ajustar `logo_file_name` y `tesseract_exe_path` de acuerdo a tu caso.

3.  ConfiguraciÃ³n del modelo (`llm.yaml`)

    Contenido:

``` yaml
# Default LLM parameters
default_llm:
  model_name: 'gpt-4o'
```

Si quieres usar otros modelos de OpenAi, puedes cambiar el nombre del modelo modificando el valor de `model_name`.

## â–¶ï¸ EjecuciÃ³n

Puedes lanzar la app ejecutando en la Terminal el siguiente comando:

``` bash
shiny run --reload app.py
```

Luego abre <http://localhost:8000> en tu navegador.

Adicionalmente, si estÃ¡s usando RStudio, puedes ejecutar la app desde el botÃ³n **Run App**, y la aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en el navegador.

![](images/clipboard-1898608170.png)

## ğŸ§  Flujo de Trabajo

1.  **Inicio**: Selecciona o crea un nuevo chat desde la barra lateral.

2.  **ConversaciÃ³n**: Escribe mensajes y el modelo responderÃ¡.

3.  **Carga de Archivos**: Adjunta un archivo PDF o imagen para extraer texto automÃ¡ticamente.

4.  **Persistencia**: La conversaciÃ³n se guarda automÃ¡ticamente.

5.  **GestiÃ³n de chats**: Puedes renombrar o eliminar cualquier conversaciÃ³n previa.

## ğŸ“ Notas TÃ©cnicas

-   La carga de archivos usa `input_file` reactivo con control de versiÃ³n.

-   Se utiliza un `MutationObserver` para hacer scroll automÃ¡tico al final del chat.

-   Los archivos anteriores se eliminan cuando se cambia de conversaciÃ³n o se inicia una nueva.

-   Las respuestas estÃ¡n limitadas a los Ãºltimos 10 mensajes para mantener el prompt eficiente.

-   El sistema agrega contexto del archivo como mensaje `system` solo si existe.

## ğŸ“Œ To-Do / Futuras mejoras

-   ğŸ” Agregar sistema de login real (actualmente solo simulado con `session_data["authenticated"]`).
-    ğŸ“Š Mostrar metadatos del archivo cargado.
-    ğŸ§© Permitir bÃºsqueda en chats antiguos.
-   ğŸŒ Soporte para otros LLMs o despliegue local.

## ğŸ“ Licencia

Este proyecto es de uso interno / acadÃ©mico / personal. ModifÃ­calo libremente segÃºn tus necesidades.
